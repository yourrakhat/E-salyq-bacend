import express from "express";
import fetch from "node-fetch";
import cors from "cors";

const app = express();

app.use(cors());
app.use(express.json());

// Ð‘ÐµÑ€Ñ‘Ð¼ ÐºÐ»ÑŽÑ‡ Ð¸Ð· Render Environment Variables
const OPENAI_KEY = process.env.OPENAI_KEY;

// ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð° (Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð² Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ðµ Ð½Ðµ Ð±Ñ‹Ð»Ð¾ Ð¾ÑˆÐ¸Ð±ÐºÐ¸)
app.get("/", (req, res) => {
  res.send("E-Salyq AI Backend is running ðŸš€");
});

// ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚ Ð´Ð»Ñ Ñ‡Ð°Ñ‚Ð°
app.post("/chat", async (req, res) => {
  try {
    const userMessage = req.body.message;

    if (!userMessage) {
      return res.status(400).json({ error: "Message is required" });
    }

    const response = await fetch(
      "https://api.openai.com/v1/chat/completions",
      {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${OPENAI_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model: "gpt-4o-mini",
          messages: [
            {
              role: "system",
              content:
                "Ð¢Ñ‹ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð½Ð°Ð»Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ð½Ñ‚ Ð´Ð»Ñ ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½Ð°. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾, Ð¿Ð¾Ð½ÑÑ‚Ð½Ð¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ."
            },
            {
              role: "user",
              content: userMessage
            }
          ]
        })
      }
    );

    const data = await response.json();

    if (data.error) {
      return res.status(500).json({ error: data.error.message });
    }

    res.json({
      reply: data.choices[0].message.content
    });

  } catch (error) {
    console.error("Server error:", error);
    res.status(500).json({ error: "Server error" });
  }
});

// âš¡ ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐž Ð´Ð»Ñ Render
const PORT = process.env.PORT || 3000;

app.listen(PORT, () => {
  console.log(`Server started on port ${PORT}`);
});
